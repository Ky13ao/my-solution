# DEP302x_01-A_VN

Data Engineering

## Lab list

- [Lab 1](#lab1---structure-designing)
- [Lab 2](#lab2---etl-initiation-with-ssis)
- [Lab 3](#lab3---transformation-trong-etl)
- [Lab 4](#lab4---fact-table-design)
- [Lab 5](#lab5---initiating-scd-slowly-changing-dimension-with-ssis)
- [Lab 6](#lab6---initiating-etl-for-dimension-table-and-fact-table)

## Data Engineering introduction

### DE là gì

#### Data ecosystem definitions

- Hệ sinh thái dữ liệu bao gồm một mạng lưới các thành phần được kết nối với nhau và liên tục phát triển bao gồm:

  - **Dữ liệu**: có sẵn ở nhiều định dạng, cấu trúc và nguồn khác nhau
  - **Môi trường Dữ liệu Doanh nghiệp**: trong đó dữ liệu thô được tổ chức, sắp xếp, làm sạch và tối ưu hóa để người dùng cuối sử dụng
  - **Người dùng cuối**: các bên liên quan doanh nghiệp, nhà phân tính và lập trình viên, những người sử dụng dữ liệu cho các mục đích khác nhau

#### Roles in DE industrial

- Có rất nhiều vai trò trong hệ sinh thái dữ liệu với từng nhiệm vụ khác nhau
  - **Data Engineer**
    - _Công việc_
      - xây dựng, bảo trì các kiến trúc dữ liệu
      - chuyển hóa dữ liệu để phù hợp cho việc phân tích nghiệp vụ
    - _Các kỹ năng cần có_
      - Kiến thức tốt về lập trình
      - Có kiến thức vững chắc về kiến thức công nghệ
      - biết rõ về các CSDL quan hệ, phi quan hệ
  - **Data Analyst**
    - _Công việc_
      - Dựa vào các dữ liệu đã được xử lý để thu thập thông tin chi tiết.
      - Xác định các mối tương quan, tìm các pattern và áp dụng các phương pháp thống kê để phân tích và khai thác dữ liệu.
      - Trực quan hóa dữ liệu.
    - _Các kỹ năng_
      - kỹ năng lập trình.
      - có kiến thức tốt về việc sử dụng bảng tính, viết truy vấn, sử dụng công cụ xác xuất để tạo dashboard và các biểu đồ.
      - có khả năng truyền đạt tốt.
  - **Data Scientist**
    - _Công việc_
      - Xây dựng các mô hình chuẩn đoán dựa vào các dữ liệu có sẵn bằng Machine Learning hoặc Deep Learning
    - _Các kỹ năng_
      - Kiến thức về Toán và Xác Xuất
      - Kiến thức về lập trình, sử dụng database và xây dựng các mô hình dữ liệu
      - Các kiến thức nghiệp vụ
  - **Business Analyst và BI Analyst**
    - _Công việc_
      - Làm việc với DA và DS để có cái nhìn tổng quan về mặt nghiệp vụ.
        Từ đó xác định được các công việc cần phải triển khai tiếp theo để phát triển doanh nghiệp
    - _Kỹ năng cần thiết_ là các kiến thức về nghiệp vụ

#### DE Definitions

##### Nhiệm vụ của các _DE_ [refer](#roles-in-de-industrial)

##### Công việc chính:

- **Thu thập dữ liệu**
  - Lấy dữ liệu từ nhiều người khác nhau
  - Đồng thời thiết kế các kiến trúc để lưu trữ dữ liệu
- **Xử lý dữ liệu**
  - Làm sạch, chuẩn hóa và chuẩn bị dữ liệu để có thể sử dụng được
    Bao gồm các bước như Trích xuất - Chuyển hóa - Tải dữ liệu (ETL)
- **Lưu trữ dữ liệu**
  - Bạn cần lưu trữ lại các dữ liệu đã được xử lý
    Hệ thống lưu trữ cần đảm bảo về tính mở rộng cũng như bảo mật
- **Xử lý dữ liệu để người dùng có thể sử dụng**
  - Bạn cần thiết kế các API
  - Các dịch vụ hoặc các Dashboard để người dùng
    có thể dễ dàng truy cập vào các dữ liệu cần thiết

##### Kỹ năng cần thiết

- Data Engineer cần có sự kết hợp các Kỹ năng chuyên môn, Kỹ năng nghiệp vụ, và các kỹ năng mềm
  - **Kỹ năng chuyên môn**
    - làm việc các hệ điều hành và các cơ sở hạ tầng khác nhau như máy ảo, mạng và dịch vụ ứng dụng
    - làm việc với Database và Data Warehouse, Data Pipeline
    - công cụ ETL, BigData và Query Languages, thao tác và xử lý dữ liệu
  - **Kỹ năng nghiệp vụ**
    - khả năng chuyển đổi các yêu cầu nghiệp vụ thành các đặc điểm kỹ thuật
    - hiểu biết về vòng đời phát triển phần mềm và các lĩnh vực
      chất lượng dữ liệu, quyền riêng tư, bảo mật và quản trị
  - **Kỹ năng mềm**
    - kỹ năng giao tiếp giữa các cá nhân
    - khả năng làm việc hợp tác, làm việc nhóm, giao tiếp hiệu quả

#### DE Ecosystem

- Hệ sinh thái của kỹ thuật dữ liệu bao gồm

  - Cơ sở hạ tầng, công cụ, khuôn khổ
  - Quy trình để trích xuất dữ liệu
    lưu trữ và quản lý quy trình dữ liệu và Data Warehouse
  - Quản lý quy trình công việc
  - Phát triển ứng dụng và quản lý các công cụ BI báo cáo

- Các dữ liệu có thể được chia thành 3 loại như sau:

  - **Dữ liệu có cấu trúc (SQL)**: Dữ liệu có định dạng có thể lưu xuống cơ sở dữ liệu
  - **Dữ liệu bán cấu trúc**: Dữ liệu có 1 phần là cấu trúc, 1 phần là tự do
  - **Dữ liệu phi cấu trúc**: Dữ liệu không thể đưa về dạng bảng để lưu trong cơ sở dữ liệu.

- Dữ liệu có nhiều định tệp khác nhau

  - chẳng hạn như:
    - Tệp văn bản được phân tách
    - Bảng tính
    - XML, PDF, JSON
  - mỗi định dạng có ưu nhược điểm riêng
  - dữ liệu cũng được trích xuất từ nhiều nguồn dữ liệu, từ cơ sở dữ liệu quan hệ và phi quan hệ
    đến API, dịch vụ web, luồng dữ liệu, nền tảng xã hội và thiết bị cảm biến

- trong việc phát triển các kho dữ liệu, thường có 2 loại chính:

  - OLTP - Online transactional processing
    - **OLTP** được thiết kế để lưu trữ một khối lượng dữ liệu **hoạt động hàng ngày** như
      - giao dịch ngân hàng trực tuyến
      - giao dịch ATM
      - đặt vé máy bay
    - mục đích của OLTP chính là bảo đảm tính chính xác và tính toàn vẹn của các giao dịch, hoạt động
  - OLAP - Online analytical processing
    - **OLAP** được tối ưu hoá để tiến hàng **phân tích dữ liệu** phức tạp
    - **OLAP** cho phép chúng ta tìm ra xu hướng, điểm mấu chốt thường phục vụ cho các mục đích phân tích

- các chuyên gia dữ liệu cần các ngôn ngữ có thể giúp họ trích xuất, chuẩn bị và phân tích dữ liệu. Ví dụ:
  - **Ngôn ngữ truy vấn** được thiết kế để truy cập và thao tác dữ liệu trong một cơ sở dữ liệu, ví dụ: SQL, ...
  - **Ngôn ngữ lập trình** được thiết kế để phát triển các ứng dụng và kiểm soát hành vi ứng dụng như Python, Java, ...
  - **Unix/ Linux shell** được thiết kế cho các tác vụ lặp đi lặp lại gây tốn nhiều thời gian.

### DE Ecosystem Definitions

#### Data Repositories overview

- **Data Repositories**

  - là 1 thuật ngữ chung đề cập đến dữ liệu và đã được thu thập, tổ chức và trích xuất
    để nó có thể được sử dụng cho báo cáo, phân tích và cũng cố cho mục đích lưu trữ
  - Có một số Data Repositories như sau
    - **Database**: Có thể là cơ sở dữ liệu quan hệ hoặc phi quan hệ, có 2 loại chính:
      - RDBMS - Relational Database Management System
        - Trong RDBMS, dữ liệu được biểu diễn bởi các hàng
        - Nó chứa các bảng và mỗi bảng có Primary Key riêng, bởi vì các bảng này được tổ chức chặt chẽ
          nên việc truy cập dữ liệu trở nên dễ dàng hơn trong RDBMS thông qua ngôn ngữ SQL
      - NoSQL - một dạng cơ sở dữ liệu sử dụng cho các dữ liệu phi cấu trúc
        - dữ liệu có thể được biểu diễn ở dạng Document, Key-Value, Graph hoặc là Column
        - NoSQL mang đến một số ưu điểm về tốc độ truy vấn cũng như tốc độ thực hiện các thao tác CRUD dữ liệu
          đồng thời cũng có thể được mở rộng và chạy trên nhiều cụm máy khác nhau
    - **Data Warehouse**: Tổng hợp và chuyển đôi các dữ liệu từ nhiều nguồn khác nhau
    - **Data Lake**: Tương tự như data warehouse, nhưng dữ liệu sẽ không được xử lý và đưa thẳng vào luôn
    - **Data Mart**: Là 1 dạng nhỏ của Data Warehouse, các dữ liệu chỉ tập trung vào 1 lĩnh vực duy nhất.
    - **Big Data Stores**: Cung cấp cơ sở hạ tầng lưu trữ và tính toán phân tán để mở rộng quy mô và xử lý các tập dữ liệu lớn

- \*\*ETL (Extract-Transform-Load)
  - là một quy trình tự động chuyển đổi dữ liệu thô thành dữ liệu có thể phân tích bằng cách:
    - **Extract** Trích xuất dữ liệu từ các nguồn dữ liệu
    - **Transform** Chuyển đổi dữ liệu thô bằng cách làm sạch, chuẩn hóa và xác thực dữ liệu đó
    - **Load** Tải dữ liệu đó vào hệ thống đích
  - ELT - một khái niệm khác với ETL
    - dữ liệu sau khi được trích xuất sẽ lưu xuống Data Lake/ Data Warehouse
    - sau đó các phép Transform mới được thực hiện ở nơi lưu trữ dữ liệu
    - quy trình này mang đến một số ưu điểm như sau
      - giảm thời gian giữa bước Trích xuất (Extract) - Phân phối (Delivery) dữ liệu
      - có thể sử dụng dữ liệu thô ngay khi chúng sẵn sàng
      - mang đến sự linh hoạt trong việc phân tích/ xử lý dữ liệu do dữ liệu chưa được biến đổi gì hết
      - ta chỉ cần thực hiện transform các dữ liệu cần thiết cho 1 nhu cầu phân tích cụ thể nào đó

#### Data Integration platform

- Nền tảng tích hợp dữ liệu
  - kết hợp các nguồn dữ liệu khác nhau, về mặt vật lý hoặc logic
    để cung cấp một cái nhìn thống nhất về dữ liệu cho các mục đích phân tích
  - bao gồm các công việc như sau:
    - Truy cập, truy vấn và trích xuất dữ liệu
    - Chuyển đổi và hợp nhất dữ liệu vừa được trích xuất
    - Quản lý về chất lượng của dữ liệu
    - Cung cấp dữ liệu thông qua cách tích hợp cho mục đích phân tích

### Quy trình DE

#### Kiến trúc của một nền tảng dữ liệu

- Kiến trúc của nền tảng dữ liệu

  - Có thể được xem như một tập hợp các tầng hoặc các thành phần chức năng
  - Mỗi tầng thực hiện một tập hợp các nhiệm vụ cụ thể
    - **Tầng thu thập dữ liệu**: bao gồm Data Warehouse
      chịu trách nhiệm đưa dữ liệu từ nguồn dữ liệu vào nền tảng dữ liệu.
    - **Tầng tích hợp và lưu trữ dữ liệu**: bao gồm ETL tools
      chịu trách nhiệm lưu trữ dữ liệu và hợp nhất dữ liệu đã trích xuất.
    - **Tầng xử lý dữ liệu**: bao gồm MongoDB
      chịu trách nhiệm xác thực, chuyển đổi và áp dụng các quy tắc nghiệp vụ cho dữ liệu
    - **Tầng phân tích và giao diện người dùng**: bao gồm MongoDB
      chịu trách nhiệm cung cấp dữ liệu đã xử lý cho người tiêu dùng dữ liệu
    - **Tầng Data Pipeline (đường ống dữ liệu)**:
      chịu trách nhiệm triển khai và duy trì quy trình
  - (Video)[https://www.coursera.org/learn/introduction-to-data-engineering/lecture/cf092/architecting-the-data-platform]

- **Data Store** hay **Data Repositories**
  - là một thuật ngữ chung đề cập đến dữ liệu đã thu thập, sắp xếp và tách biệt
    để nó có thể sử dụng cho báo cáo, phân tích và cũng cho mục đích lưu trữ
  - việc lựa chọn hoặc thiết kế 1 Data Store ảnh hưởng bởi
    - loại dữ liệu và khối lượng dữ liệu cần được lưu trữ
    - mục đích sử dụng dữ liệu
  - các nhu cầu về quyền riêng tư, bảo mật và quản trị của tổ chức của bạn
    cũng ảnh hưởng đến sự lựa chọn nào
  - Video:
    - [Các yếu tố để lựa chọn và thiết kế Datastore](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/b4RA9/factors-for-selecting-and-designing-data-stores)
    - [Bảo mật](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/weR2q/security)

#### Thu thập và làm gọn dữ liệu

- Các cách riêng biệt để thu thập dữ liệu từ các Data Source khác nhau

  - SQL Query
    - truy vấn và lấy dữ liệu từ Database
    - đồng thời SQL cũng hỗ trợ các thao tác như `Group`, `Count`,...
    - với các Database thuộc dạng NoSQL thì cũng sẽ có các công cụ truy vấn như GraphQL,...
  - API
    - thường được sử dụng để thu thập dữ liệu từ các data source
    - khi được thực thi từ các ứng dụng cần dữ liệu, API sẽ truy cập vào Database
      truy vấn và trả về dữ liệu cần thiết
  - Web Scraping
    - là phương pháp thu thập, trích xuất dữ liệu dạng text, ảnh, video,...
      từ các trang web
  - Data Stream
    - là phương pháp để tổng hợp các dữ liệu liên tục
    - phù hợp để thu thập các dữ liệu từ IoT, cảm biến, hoặc các ứng dụng thời gian thực
  - Data Exchanges:
    - cho phép trao đổi dữ liệu giữa bên cung cấp và bên cần sử dụng dữ liệu
  - video [cách để thu thập và nhập dữ liệu](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/745p6/how-to-gather-and-import-data)

- Làm gọn dữ liệu

  - liên quan đến các hoạt động biến đổi và làm sạch được thực hiện trên dữ liệu
  - chuyển đổi dữ liệu thô bao gồm các nhiệm vụ bạn thực hiện như sau
    - kết hợp các dữ liệu bằng cách `JOIN` và `UNIONS`
    - chuẩn hóa dữ liệu, tức là làm sạch database của dữ liệu thừa
    - kết hợp dữ liệu từ nhiều bảng thành một bảng duy nhất để có thể truy vấn nhanh hơn
  - video [Làm gọn dữ liệu](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/WLz3F/data-wrangling)
  - video [các công cụ cho việc làm gọn dữ liệu](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/ngaMF/tools-for-data-wrangling)
  - sau khi đã nhập dữ liệu thành công thì dữ liệu đó đã có thể được phân tích
  - chúng ta cũng có 1 số thao tác phân tích dữ liệu cơ bản như sau:
    - **Counting** đếm số lượng Row, Record trong tập dữ liệu
    - **Aggregation** Tổng hợp dữ liệu từ nhiều khía cạnh khác nhau để có 1 cái nhìn tổng quát hơn
    - **Extreme Value Identification** xác định các cực trị trong dữ liệu, ví dụ như MIN, MAX,...
    - **Slicing Data** tìm các dữ liệu dựa trên một tập các điều kiện
    - **Sorting Data** sắp xếp lại dữ liệu dựa trên các điều kiện
    - **Filtering Patterns** lọc các dữ liệu cần thiết
  - video [truy vấn và phân tích dữ liệu](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/WpGrK/querying-and-analyzing-data)

- vòng đời kỹ thuật dữ liệu
  - cần phải theo dõi liên tục hiệu suất và tính khả dụng về:
    - Data Pipelines
    - hiệu suất của data pipelines có thể bị ảnh hưởng nếu
      - khối lượng công việc tăng lên đáng kể
      - có lỗi ứng dụng hoặc các Task đã lên lịch không hoạt động như mong đợi
    - các nền tảng
    - Databases
    - ứng dụng, công cụ, truy vấn và lập lịch
      - một số cung cụ trong Data Pipelines gặp sự cố tương thích
    - cơ sở dữ liệu dễ bị ngừng hoạt động, sử dụng quá mức dung lượng
    - ứng dụng chạy chậm
    - các truy vấn bị xung đột khi thực thi đồng thời
  - chúng ta cần một hệ thống giám sât hiệu suất
    hệ thống giám sát và cảnh báo sẽ
    - thu thập dữ liệu định lượng
    - trong thời gian thực
    - để cung cấp khả năng hiển thị về hiệu suất
      - Data Pipelines, nền tảng, Databases
      - ứng dụng, công cụ, truy vấn, lập lịch,...
    - và cũng cần có lịch trình bảo trì
      - dựa trên thời gian và điều kiện tạo ra dữ liệu
      - giúp xác định các hệ thống và quy trình chịu trách nhiệm về lỗi và tính khả dụng thấp
  - video [hiệu suất](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/5PkCj/performance-tuning-and-troubleshooting)

### Cơ hội nghề nghiệp trong DE

- DE được báo cáo là một trong mười ngành hàng đầu có tốc độ phát triển vượt bậc ở Hoa Kỳ hiện nay
- Nó cũng được báo cáo là 1 trong những ngành công nghệ phát triển nhanh nhất với mức tăng trưởng hàng năm khoảng 50%
- Hiện tại, nhu cầu vễ các Data Engineer có tay nghề cao hơn nhiều so với nguồn cung, có nghĩa là các công ty sẵn sàng trả một khoản phí cao để thuê các Kỹ sư dữ liệu có tay nghề cao
- Data Engineer có thể đảm nhiều rất nhiều vai trò quan trọng, các vai trò này sẽ phụ thuộc vào công ty mà bạn đang làm việc
- Tuy nhiên thông thường sẽ được chia thành các mảng như sau:
  - Data Architecture
  - Database Design and Architecture
  - Data Platforms
  - Data Pipelines and ETL
  - Data Warehouses
  - Big Data
- Từ đó cũng sẽ có những vai trò trong DE như sau:
  - Data Architect
  - Database Architect
  - ETL Engineer
  - Data Warehouse Engineer
  - Big Data Engineer
- Video [Cơ hội nghề nghiệp trong ngành DE](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/thWrv/career-opportunities-in-data-engineering)
- Video [Con đường học tập về ngành DE](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/Cs66I/data-engineering-learning-path)
- Video [Góc nhìn: Nhà tuyển dụng tìm kiếm gì ở 1 Data Engineer](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/S0xc4/viewpoints-what-do-employers-look-for-in-a-data-engineer)
- Video [Góc nhìn: Nhiều con đường dẫn đến DE](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/5J5rb/viewpoints-the-many-paths-to-data-engineering)
- Video [Góc nhìn: Lời khuyên cho các kỹ sư dữ liệu](https://www.coursera.org/learn/introduction-to-data-engineering/lecture/W23Fb/viewpoints-advice-to-aspiring-data-engineers)

## Data Warehousing - Storing data

### Khái niệm về DW

#### Tính chất và lợi ích của DW

- là 1 kỹ thuật thu thập và quản lý dữ liệu từ nhiều nguồn khác nhau để cung cấp những thông tin kinh doanh có ý nghĩa
- các tính chất của Data Warehouse
  - **Được tích hợp (Integrated)**
    - Dữ liệu trong DW sẽ được lấy từ nhiều nguồn dữ liệu **(Data Source)** khách nhau để có được đầy đủ thông tin
  - **Hướng chủ đề (Subject oriented)**
    - Tổ chức dữ liệu theo chủ đề để thuận tiện cho việc phân tích
    - Ví dụ:
      - với chủ đề nhân sự thì có thể bao gồm
        - các độ đo về doanh thu của từng người, số ngày nghỉ trong tháng, số dự án tham gia trong tháng,...
        - theo các chiều phân tích: thời gian, chi nhánh, sản phẩm,...
    - chỉ lưu trữ các dữ liệu cần thiết cho công việc phân tích
      không cần những dữ liệu thừa khác
  - **Có gán nhãn thời gian (Time variant)**:
    - các dữ liệu sẽ được gán 1 nhãn thời gian tương ứng
      có thể lưu lại được các dữ liệu lịch sử **(historical data)**.
    - dữ liệu lịch sử có tầm quan trọng đặc biệt trong phân tích dữ liệu
    - cùng một độ đo sẽ có nhiều giá trị khác nhau trong lịch sử
    - có thể dùng để so sánh với nhau để biết được sự thay đổi là tốt hay xấu
  - **Bất biến (Non volatile)**
    - khác với Database thì Data Warehouse chỉ có hai thao tác chính là đọc và ghi dữ liệu
    - dữ liệu sẽ ko thể bị thay đổi, cập nhật do như vậy sẽ không phản ánh đúng với thực tế
  - [data warehouse](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L1_1.JPG.png?alt=media&token=5a38d1cc-1238-4c5e-89bf-f37529109401)
  - video [khái niệm DW](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728264#overview)
- các lợi ích khi sử dụng Data Warehouse
  - Hỗ trợ đưa ra quyết định theo hướng dữ liệu
  - **One Stop Shopping**
    - tất cả dữ liệu (từ nhiều nguồn khác nhau) được tập trung về 1 chỗ.
    - giúp cho ta chỉ cần tập trung vào việc phân tích dữ liệu
      mà không cần phải lo việc thu thập dữ liệu nữa
  - video [tại sao lại cần DW](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728274#overview)

#### So sánh DW và **Data Lake**

- Cơ sở
  - DW thường được xây dựng trên một RDB hoặc hệ CSDL đa chiều **(Multidimensional Database)**
  - Data Lake thường được xây dựng trên 1 môi trường Big Data
- Công dụng
  - DW biến đổi và phân loại dữ liệu từ các nguồn khác nhau của doanh nghiệp.
    Dữ liệu này sẽ sẵn sàng để phục vụ cho các mục đích khác đặc biệt là báo cáo và phân tích
  - Data Lake lưu trữ dữ liệu chưa qua phân tích và giữ trong trạng thái thô.
    Những dữ liệu này cần được xử lý thêm khi có nhu cầu sử dụng
- Đặc tính
  - DW gồm các dữ liệu có cấu trúc cụ thể
  - Data Lake có thể chứa tất cả các loại dữ liệu.
- [So sánh Data Warehouse với Data Lake](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L1_2.JPG.png?alt=media&token=09f0f441-8d9f-4b6f-b0ea-063fe4181b7c)
- Video [So sánh Data Warehouse với Data Lake](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728282#overview)

#### So sánh Data Warehouse với Data Visualization

- Data Visualization hay bị nhầm lẫn với Data Warehouse về khái niệm
- Một số điểm khác biệt của Data Visualization như sau:
  - là 1 cơ sở dữ liệu quan hệ Readonly (các dữ liệu chỉ đọc)
  - trong quá trình phân tích, thống kê thì sẽ truy cập trực tiếp vào Database
    thay vì phải sao chép dữ liệu về 1 chỗ khác
- Chúng ta có thể thấy được Data Visualization nên được sử dụng trong các trường hợp sau:
  - Không yêu cầu các phép biến đổi dữ liệu quá nặng
  - số lượng nguồn dữ liệu ít
  - thời gian thực hiện truy vấn không quá quan trọng
- Video [So sánh](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728284#overview)

#### Quy trình DW đầu cuối

- Dữ liệu từ nhiều nguồn (datasource) qua quá trình ETL sẽ được đưa vào DW
- Đôi khi, các dữ liệu sẽ được tiếp tục chuyển đến cho các môi trường nhỏ hơn như Data Mart
- [quy trình DW](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L1_3.png?alt=media&token=1b3ca1cf-2ee6-4791-87d6-9ecacd75a545)
- video [Quy trình Data Warehouse đầu cuối](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728292#overview)

#### Lựa chọn giữa Cloud và On-Premises Setting

- Ưu điểm khi dùng Cloud
  - Giảm tải bảo trì và cập nhật hệ thống định kỳ
  - Chi phí đầu tư nền tảng có thể thấp hơn
  - Dễ dàng khắc phục các tai nạn hệ thống
  - Có thể kết hợp với Data Lake và Big Data
- Nhược điểm Cloud so với OnPremises
  - Bảo mật thấp hơn
  - Khó để chuyển dữ liệu từ OnPremises Data Warehouse sang Cloud
  - Khó để chuyển dữ liệu giữa data center và cloud
- [các kiến trúc tương ứng](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L12_1.png?alt=media&token=a6090acc-112a-4943-9ea8-0c80df4effa8)
- video [Lựa chọn giữa cloud và onpremises](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729392#overview)
- video [các kiến trúc tương ứng](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729396#overview)

### Các kiến trúc DW

#### Centralized DW

- 1 môi trường chỉ gồm 1 DW duy nhất, tất cả các dữ liệu đều được lưu ở đây
- Kiến trúc này mang đến 1 số ưu điểm sau
  - One Stop Shopping (một điểm dừng): tất cả dữ liệu (từ nhiều nguồn khác nhau)
    được tập trung về một chỗ giúp việc phân tích dễ dàng hơn
  - Dễ dàng vẽ các sơ đồ thiết kế
- Tuy có một số vấn đề về mặt công nghệ, quy trình hoạt động nhưng đến nay đã được giải quyết
- Video: [Centralized Data Warehouse](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728412#overview)

#### So sánh DW vs Data Mart

- dữ liệu không cần dừng lại ở Data Warehouse mà có thể chuyển xuống các môi trường nhỏ hơn như DataMart
- **Data Mart** là một tập hợp nhỏ của DW, thường chỉ tập trung vào 1 lĩnh vực duy nhất, vd DataMart về sale, về khách hàng,...
- vì vậy, data mart sẽ nhỏ và linh hoạt hơn
  khi phân tích về một lĩnh vực nhỏ thì sẽ chỉ cần dùng dữ liệu từ Data Mart tương ứng chứ không cần tìm trong Data Warehouse
- có 2 loại data mart
  - Dependent Data Mart
    - dữ liệu được lấy từ Data Warehouse
    - Các dữ liệu sẽ đồng nhất với nhau
  - Indepent Data Mart
    - dữ liệu được lấy trực tiếp từ các data source
    - các dữ liệu không nhất thiết phải đồng nhất với nhau
- như vậy, DW khá giống với Independent Data Mart, ta có sự khác biệt như sau
  - DW: dữ liệu được lấy từ rất nhiều nguồn
  - Independent Data Mart: dữ liệu được lấy từ 1 số nguồn

#### Lựa chọn cấu trúc phù hợp nhất

- Khác với centralized, kiến trúc Component-Based sẽ gồm nhiều thành phần (DW, Data Mart hoặc Data Lake) liên kết với nhau
- Để lựa chọn cấu trúc phù hợp nhất, đầu tiên ta cần chọn giữa Centralized và Component-Based
- Centralized
  - Ưu điểm
    - Là phương án mặc định
    - One Stop shopping
    - công nghệ hiện đại
  - Nhược điểm
    - Các tổ chức cần liên kết chặt chẽ với nhau
    - khả năng quản lý dữ liệu phải tốt
    - có thể xảy ra ripple effect
      khi một dữ liệu thay đổi có thể ảnh hưởng đến toàn bộ dữ liệu
- Component-Based
  - Ưu điểm
    - Hỗ trợ Mix-and-Match
    - Có thể liên kết với thành phần với nhau
    - Dễ xử lý các vấn đề liên quan đến lưu trữ dữ liệu
  - Nhược điểm
    - Các dữ liệu thường ko nhất quán với nhau
    - Khó để tích hợp chéo

#### Database đa chiều trong DW

- Ngoại trừ RDBMS, ta còn có thể sử dụng CSDL đa chiều MDBMS, MDBMS thường sẽ phù hợp với các Data Warehouse có quy mô nhỏ
- Ưu điểm
  - Thời gian truy xuất dữ liệu nhanh
  - Dung lương lưu trữ ko quá lớn
- Nhược điểm
  - Cấu trúc ít linh hoạt hơn RDBMS
  - Có nhiều sự biến thể hơn RDBMS
- Video: [Database đa chiều trong DW](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728568#overview)

#### ODS trong DW

- Ngoài DW, ta còn có thể sử dụng oDS(Operational Data Store)
- ODS giống như DW nhưng khi dữ liệu được cập nhật sẽ ghi đè lên dữ liệu
  dẫn đến ODS sẽ không có các dữ liệu lịch sử (Historical Data)
- video [ODS trong DW](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728580#overview)

#### Staging Layer trong DW

- **Staging Layer (tầng trung gian)**
  - là khu vực thực h iện việc xử lý thông tin cũng như lưu trữ trước khi đưa vào DW
- **User Access Layer(tầng người cùng truy cập)**
  - là khu vực mà user có thể truy cập được vào dữ liệu
- [Staging layer & User access layer](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L6_1.png?alt=media&token=ea681db1-b950-4f8e-8510-6d3788ceb9e1)
- Staging Layer được chia làm 2 loại
  - Non Persistent(không liên tục)
    - Sau khi đưa dữ liệu vào DW thì sẽ xóa dữ liệu của ở Staging Layer đi
    - Ưu điểm
      - Lưu trữ ít hơn
      - Dữ liệu đc chuyển hẳn sang User Layer
    - Nhược điểm
      - Khi user layer gặp lỗi và cần dừng lại thì sẽ phải lấy lại các dữ liệu từ Data Source
      - Việc đảm bảo chất lượng dữ liệu cũng cần đến Data Store
  - Persistent (liên tục)
    - Sau khi đưa dữ liệu vào DW thì vẫn giữ dữ liệu cũ ở Staging Layer
    - Ưu điểm
      - Khi User layer gặp lỗi và cần dựng lại thì có thể lấy trực tiếp từ Staging Layer
      - Để đảm bảo chất lượng dữ liệu thì cần so sánh giữa User Layer và Staging Layer
    - Nhược điểm
      - Phải truy cập nhiều hơn
      - Có rủi ro bị truy cập trái phép
  - video [staging layer trong DW](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728588#overview)
  - video [các loại staging layer](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728608#overview)

### Lab1 - Structure designing

- Đề bài [shortcut](https://courses.funix.edu.vn/courses/course-v1:FUNiX+DEP302x_01-A_VN+2021_T8/courseware/3a8c750402a24420904c42983322073a/fdd45c0e3ad0432488b2fb9d09d8e66f/?activate_block_id=block-v1%3AFUNiX%2BDEP302x_01-A_VN%2B2021_T8%2Btype%40sequential%2Bblock%40fdd45c0e3ad0432488b2fb9d09d8e66f)

- Bài giải: xem file "lab1.dio"

### Load data to DW

#### ETL & ELT comparison

- ETL viết tắt cho:

  - Trích xuất (Extract):
    Lấy dữ liệu từ các Data Source theo từng lô
    bao gồm tất cả dữ liệu thô (chưa qua xử lý) và chuyển đến Staging Layer.
  - Chuyển đổi (Transform):
    Biến đổi để dữ liệu từ nhiều nguồn đồng nhất với nhau.
    Quá trình này có thể rất phức tạp.
  - Tải (Load):
    Chuyển các dữ liệu đã được biến đổi vào User Access Layer.

- RDBMS (Relational Database Management System)
  là hệ quản trị cơ sở dữ liệu quan hệ. RDBMS sử dụng các bảng để lưu trữ dữ liệu.
  Một bảng là một tập hợp các dữ liệu có liên quan và chứa các hàng và các cột để lưu dữ liệu.

- MDBMS (Multidimensional Database Management System)
  là hệ quản trị cơ sở dữ liệu đa chiều.
  Các dữ liệu sẽ được cấu trúc theo nhiều chiều, mỗi chiều mô tả một đặc trưng nào đó của dữ liệu.
  MDBMS còn có một tên gọi khác là Cube.

- ETL

  - Dữ liệu được lưu trữ và xử lý ở Staging Layer sau đó mới chuyển vào Data Warehouse.
    [figure](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L7_2.png.png?alt=media&token=4a46476a-5e23-410a-9522-c7da56cd479e)
  - Phù hợp với các môi trường dùng RDBMS hoặc MDBMS.

- ELT

  - Dữ liệu thô được đưa vào Data Warehouse. Khi phân tích thì mới bắt đầu biến đổi.
    [figure](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L7_1.png.png?alt=media&token=1c10d640-bde0-4fb7-ad34-05441d47f6cf)
  - Phù hợp với các môi trường dùng Big Data.

- video [So sánh giữa ETL và ELT](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728682#overview)

#### Initial Load ETL và Incremental ETL

- BI (Business Intelligence)

  - là một quy trình có khả năng tích hợp công nghệ
  - giúp các doanh nghiệp kiểm soát khối lượng dữ liệu khổng lồ đến từ
    nhiều nguồn khác nhau và khai thác nguồn dữ liệu đó một cách hiệu quả.
  - Đồng thời hệ thống tạo ra những tri thức (knowledge) mới giúp cho các nhà quản lý
    có thể đưa ra các quyết định hiệu quả hơn trong hoạt động kinh doanh của mình.

- Initial Load ETL (ETL tải ban đầu)

  - là một biến thể của ETL, gồm một số đặc điểm sau:
    - Chỉ xảy ra một lần trước khi Data Warehouse được đưa vào vận hành.
    - Đưa tất cả các dữ liệu cần thiết cho việc phân tích và BI vào Data Warehouse.
    - Có thể thực hiện lại nếu Data Warehouse gặp lỗi và cần khởi động lại.
  - Video: [Initial Load ETL](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728684#overview)

- Incremental ETL (ETL gia tăng)
  - cũng là một biến thể của ETL
  - mục đích là giữ cho các dữ liệu luôn mới nhất
  - bằng cách thêm các dữ liệu mới hoặc cập nhật các dữ liệu cũ.
  - Ngoài ra, Incremental ETL cũng xử lý việc xóa dữ liệu.
    Lúc này thì dữ liệu sẽ không bị xóa hẳn khỏi Data Warehouse
    mà chỉ đánh dấu là không còn active nữa.
  - _Bốn thao tác trong Incremental ETL_:
    - **Append**: Chèn thêm dữ liệu vào Data Warehouse.
    - **In-place Update**: Thay đổi một số dữ liệu có sẵn.
    - **Complete replacement**: Thay đổi toàn bộ dữ liệu có sẵn.
    - **Rolling append**: Thường được sử dụng trong việc quản lý dữ liệu theo thời gian. Khi chèn thêm một dữ liệu mới thì sẽ xóa dữ liệu cũ tương ứng đi.
  - Video: [Incremental ETL](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728686#overview)

#### Tầm quan trọng của việc Transform dữ liệu

- Bước Transform giúp các dữ liệu đồng nhất với nhau và phù hợp về mặt nghiệp vụ.
- Do Data Warehouse lấy dữ liệu từ rất nhiều nguồn khác nhau nên bước Transform này rất quan trọng.

- Các mô hình Transform:
  - Đồng nhất về giá trị.
  - Đồng nhất về loại và kích thước của dữ liệu.
  - Loại bỏ các dữ liệu trùng nhau.
  - Video: [Tầm quan trọng của việc Transform dữ liệu](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728696#overview)
  - Loại bỏ các cột không cần thiết.
  - Loại bỏ các hàng không cần thiết.
  - Sửa các lỗi được phát hiện.
  - Video: [Các mô hình Transform khác với ETL](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728698#overview)

#### Mix-and-Match Incremental ETL

- Thực tế, Data Warehouse sẽ không lấy dữ liệu từ tất cả các Data Source cùng một thời gian
- có Data Source sẽ lấy dữ liệu hàng tháng, hoặc hàng giờ,…
- Và mỗi Data Source cũng sẽ sử dụng một mô hình chuyển đổi khác nhau.
- vì vậy, Mix-and-Match (pha trộn và kết hợp) là phương pháp kết hợp nhiều mô hình chuyển đổi với nhau.
- Video: [Mix-and-Match Incremental ETL](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728702#overview)

### Lab2 - ETL initiation with SSIS

- Đề bài [shortcut](https://courses.funix.edu.vn/courses/course-v1:FUNiX+DEP302x_01-A_VN+2021_T8/courseware/3a8c750402a24420904c42983322073a/98656d6d42a6422a90de08708d73ad62/?activate_block_id=block-v1%3AFUNiX%2BDEP302x_01-A_VN%2B2021_T8%2Btype%40sequential%2Bblock%4098656d6d42a6422a90de08708d73ad62)

- Bài giải: Xem SSISProject1 solution

### DW contruction

#### Xác định mục đích sử dụng

- Để bắt đầu xây dựng 1 DW, chúng ta cần dựa vào mục đích sử dụng, từ đó chọn ra được model sử dụng
- BI category drives data model
  - Basic reporting - Dimensional
  - Online analytical processing (OLAP) - Dimensional
  - Predictive analytics - Data mining/specialized
  - Exploratory analytics - Data mining/specialized
- Video: [Xác định xem Data Warehouse được sử dụng cho mục đích gì](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728858#overview)
- Video: [Các nguyên tắc cơ bản của Dimensionality (kích thước)](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728864#overview)

#### Facts, Fact Tables, Dimensions va Dimension Tables

##### Facts

- Thường là phép đo (measure), số liệu (metrics) hoặc sự kiện (fact) của quy trình kinh doanh (business process).
  _Ví dụ_: điểm số, thù lao, ... => Fact Table là một bảng chứa các Fact.
- Fact có thể được chia ra làm 3 loại:
  - **Additive**:
    là những Fact có thể được tổng hợp thông qua tất cả các Dimension trong Fact Table.
  - **Semi-Additive**:
    là những Fact có thể được tóm tắt cho một số Dimension trong Fact Table chứ không phải là những bảng khác.
  - **Non-Additive**:
    là những Fact không được tóm tắt cho bất kỳ Dimension hiện tại nào trong Fact Table.

##### Dimensions

- Cung cấp các thông tin, ngữ cảnh cho Fact.
  _Ví dụ_: tên môn học, tên công ty, ... => Dimension Table là một bảng chứa các Dimension.

##### Video:

- [Facts, Fact Tables, Dimensions, và Dimension Tables](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728874#overview)
- [Phân loại Fact](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728882#overview)

#### Star Schema và Snowflake Schema

##### Star Schema

- Định nghĩa
  - Gồm 1 Fact Table nằm ở trung tâm và được bao quanh bởi những Dimension Table
  - Dữ liệu không được chuẩn hoá.
- Ví dụ
  - ![star schema image](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L8_1.png?alt=media&token=6414cbca-f966-4b1f-afad-950bfdca692b)
- Ưu điểm
  - Fact Table, Dimension Table được mô tả rõ ràng, dễ hiểu.
  - Khoá của Fact Table được tạo bởi khoá của các Dimension Table.
    Nghĩa là khoá chính của các Dimension Table chính là khoá của Fact Table.
- Nhược điểm
  - Dữ liệu không được chuẩn hóa.

##### Snowflake Schema

- Định nghĩa
  - Là dạng mở rộng của Star Schema bằng cách chuẩn hóa các Dimension Table.
  - Dữ liệu được chuẩn hoá.
- Ví dụ
  - ![snow schema image](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L8_3.png?alt=media&token=f4d147ac-5fbf-45ca-a9ec-416b6c4832e8)
- Ưu điểm
  - Số chiều được phân cấp thể hiện dạng chuẩn của Dimension Table.
  - Các Dimension Table sử dụng ít bộ nhớ hơn.
- Nhược điểm - Cần thực hiện các bước JOIN bảng để lấy dữ liệu.

##### Video

- [Star Schema và Snowflake Schema](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728890#overview)

#### Database Keys trong Data Warehousing

- Khóa chính (Primary Key) trong Datawarehouse được chia thành 2 loại:
  - Surrogate Key:
    - Là khóa chính dimension table thường có giá trị là kiểu số.
    - Thường được hệ thống DW sinh ra (duy nhất) bằng các luồng ETL.
    - Tuy nhiên đây là khóa không có ý nghĩa trong ngữ cảnh nghiệp vụ.
  - Natural Key:
    - Là loại khoá sử dụng chính một hoặc kết hợp nhiều thuộc tính
      có sẵn của đối tượng lưu trữ trong CSDL để làm khoá
      ⇒ có ý nghĩa trong ngữ cảnh nghiệp vụ.
- Video: [Database Keys trong Data Warehousing](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17728892#overview)

### Lab3 - Transformation trong ETL

- đề bài lab3 [shortcut](https://courses.funix.edu.vn/courses/course-v1:FUNiX+DEP302x_01-A_VN+2021_T8/courseware/3a8c750402a24420904c42983322073a/22b0c6a2a9d74be2a2b5479f70683a46/?child=first)

- Bài giải: Xem SSISProject1 solution

### Fact Tables and Dimension Tables designing

- Cách thiết kế Dimension, Fact Tables cho Star Schemas và Snowflake Schemas, với dimension table:
  - Star Schemas: Chỉ có 1 bảng duy nhất chứa toàn bộ thông tin.
  - Snowflake Schemas: Chia ra các bảng con và kết nối với nhau bằng Primary Key and Foreign key.
- video [Thiết kế Dimension Tables cho Star Schemas và Snowflake Schemas](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729122#overview)
- video [So sánh về cấu trúc của Fact Tables trong Star Schemas và Snowflake Schemas](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729276#overview)

- Fact Table được chia thành 4 loại chính:

  - Video [4 Fact Table loại chính](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729218#overview)
  - Transaction
    - Dữ liệu chủ yếu là các Additive Facts được lưu lại từ các giao dịch.
    - có thể được coi là loại được sử dụng nhiều nhất.
    - Được sử dụng để lưu lại thông tin cụ thể của mỗi giao dịch ( mỗi record sẽ là một giao dịch).
    - các Transaction này phải có đầy đủ thông tin về thời gian xảy ra để có thể dễ dàng phân tích hơn.
    - Bảng cũng chứa nhiều khóa ngoại vì có mối quan hệ với Dimension Table.
    - Video: [Nhiệm vụ của Transaction Fact Tables](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729222#overview)
    - Video: [Rules Governing Facts và Transaction Fact Tables](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729234#overview)
  - Periodic Snapshot
    - Bảng này lưu trữ Snapshot quy trình kinh doanh trong một khoảng thời gian cụ thể.
    - Trong bảng dữ liệu này có thể không ở cấp độ quy trình kinh doanh
    - Nó tóm tất hoạt động trong một khoảng thời gianm có thể là tháng, năm hoặc tuần.
    - ví dụ [Tracking student meal card payments](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L9_1.png?alt=media&token=5eb892b3-9fae-4517-bf45-191bda2afaab)
    - video [Vai trò của Periodic Snapshot Fact Tables](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729242#overview)
    - video [Periodic Snapshots và Semi-Additive Facts](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729250#overview)
  - Accumulating Snapshot
    - Đại diện cho toàn bộ vòng đời của quy trình kinh doanh từ đầu đến cuối quy trình.
      ( tức là "Xử lý đơn hàng bán hàng", "Xử lý yêu cầu")
    - Mỗi bản ghi trong loại bảng này đại diện cho một thực thể
      của quy trình kinh doanh tương ứng
      sau đó bản ghi này sẽ được cập nhật mỗi lần theo trạng thái hiện tại của thực thể
    - ví dụ:
      Chúng ta đang xử lý một đơn đặt hàng.
      Mỗi khi trạng thái của đơn hàng đó (Đã đặt, đã chuẩn bị hàng, đang vận chuyển, đã vận chuyển, ...) được cập nhật
      thì dữ liệu tương ứng ở Fact table cũng sẽ được cập nhật.
    - Video: [Vai trò của Accumulating Snapshot Fact Tables](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729254#overview)
    - Video: [Ví dụ về Accumulating Snapshot Fact Table](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729264#overview)
  - Factless
    - Dữ liệu không bao gồm một Fact nào hết.
    - Do có một số sự kiện không có số liệu thước đo
      Nên Fact Table sẽ chỉ gồm các PK và FK
    - Các bảng này được sử dụng để nắm bắt các hành động của quy trình kinh doanh
    - Ví dụ [Fact leave](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP302x%2FSummary_Image%2FDEP302_sum_L9_2.png?alt=media&token=c3945030-aafe-41af-9eed-a066c736588e)

- Khóa chính và Khóa ngoại cho Fact Table
  - **Primary Key** trong Fact Table sẽ là tổng hợp của tất cả các Foreign Key
    liên kết với các Dimension Table có liên quan (kể cả khi bảng đã có Nature Key).
  - **Foreign Key** trong Fact Table sẽ liên kết với các Dimension Table có liên quan.
  - Video: [Khóa chính và Khóa Ngoại cho Fact Table](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729238#overview)

### Lab4 - Fact Table design

- Đề bài : [shortcut](https://courses.funix.edu.vn/courses/course-v1:FUNiX+DEP302x_01-A_VN+2021_T8/courseware/3a8c750402a24420904c42983322073a/ef648f3b92ff41868339cf62884ce0ff/?child=last)

- Bài giải : xem lab4.dio

### DW version control

1. Slowly Changing Dimensions (SCDs) và lịch sử của Data Warehouse

- DW sẽ lưu lại các dữ liệu trong quá khứ (Time variant)
  Nên chúng ta cần dùng SCD để quản lý lịch sử của dữ liệu trong DW

- Từ đó chia ra làm 3 loại SCD:

  - Loại 1:
    - Kỹ thuật
      - In-place update
      - Đơn giản là thay đổi giá trị cũ thành mới
    - Tính chất
      - Đây là loại đơn giản nhất nhưng sẽ không giữ được các dữ liệu cũ
  - Loại 2:
    - Kỹ thuật
      - Khi có thay đổi thì sẽ chèn thêm 1 hàng nữa chứa các giá trị update mới
        => Giữ cả 2 version cũ và mới
    - Tính chất
      - Phức tạp về mặt kỹ thuật nhưng sẽ giữ lại được các dữ liệu cũ
  - Loại 3:
    - Kỹ thuật
      - Khi thay đổi dữ liệu thì sẽ có 2 cột: 1 cột chứa giá trị cũ, 1 cột chứa giá trị mới
    - Tính chất
      - Ưu điểm: Không tăng kích thước của bảng và có thể giữ lại được các dữ liệu cũ
      - Khuyết điểm: Sẽ không giữ được các dữ liệu cũ nếu bị thay đổi nhiều lần

- Video: [Slowly Changing Dimensions (SCDs) và lịch sử của Data Warehouse](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729308#overview)
- Video: [Thiết kế SCD loại 1](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729310#overview)
- Video: [Thiết kế SCD loại 2](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729312#overview)
- Video: [Thiết kế SCD loại 3](https://funix.udemy.com/course/data-warehouse-fundamentals-for-beginners/learn/lecture/17729318#overview)

2. Duy trì thứ tự dữ liệu chính xác với SCD loại 2

- Nếu như sử dụng SCD loại 2 thì chúng ta sẽ không biết được đâu là giữ liệu mới nhất. Có một số giải pháp như sau:
  - **Current_Flag**: Thêm 1 cột current_flag đánh dấu xem đó có phải là giá trị mới nhất không.
  - **Eff_date** and **Exp_date**: Thêm 2 cột để thể hiện ngày dữ liệu được thêm và ngày dữ liệu bị thay đổi.

### Lab5 - Initiating SCD (Slowly Changing Dimension) with SSIS

### ETL designing

### Lab6 - Initiating ETL for Dimension Table and Fact Table

### Assignment1: DW contruction

## MongoDB

## Web scrapping with Python

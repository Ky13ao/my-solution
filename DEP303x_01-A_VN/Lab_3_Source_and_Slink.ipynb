{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaL70vgSqsqe"
      },
      "source": [
        "# Lab 3: Source and Slink\n",
        "\n",
        "## Tổng quan bài tập\n",
        "**Đề bài**: Dựa vào tập dữ liệu, hãy đọc dữ liệu từ Dataset và tạo Schema hợp lý và phân vùng lại dữ liệu. Hãy hoàn thiện các phần `[...]` để hoàn thiện đoạn code và giải quyết bài toán trên.\n",
        "\n",
        "## Tài nguyên tham khảo\n",
        "\n",
        "Bạn có thể tải tập Dataset tại [link sau](https://drive.google.com/file/d/1X-6xQafkMwDU39xBfEdItDwqg8N_6WV9/view?usp=sharing). Sau đó đưa lên Google Drive và kết nối với Colab là có thể sử dụng được. Tập dữ liệu là file .csv sẽ có cấu trúc như sau:\n",
        "```\n",
        "root\n",
        " |-- FL_DATE: date (nullable = true)\n",
        " |-- OP_CARRIER: string (nullable = true)\n",
        " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
        " |-- ORIGIN: string (nullable = true)\n",
        " |-- ORIGIN_CITY_NAME: string (nullable = true)\n",
        " |-- DEST: string (nullable = true)\n",
        " |-- DEST_CITY_NAME: string (nullable = true)\n",
        " |-- CRS_DEP_TIME: integer (nullable = true)\n",
        " |-- DEP_TIME: integer (nullable = true)\n",
        " |-- WHEELS_ON: integer (nullable = true)\n",
        " |-- TAXI_IN: integer (nullable = true)\n",
        " |-- CRS_ARR_TIME: integer (nullable = true)\n",
        " |-- ARR_TIME: integer (nullable = true)\n",
        " |-- CANCELLED: integer (nullable = true)\n",
        " |-- DISTANCE: integer (nullable = true)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPRu5D4IfO3I"
      },
      "source": [
        "# Cài đặt Spark trên Google Colab\n",
        "\n",
        "Để có thể sử dụng Spark trên môi trường Google Colab thì bạn sẽ cần cài đặt một số thành phần sau:\n",
        "- Java 8\n",
        "- Spark Binary\n",
        "- findspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHdKMp8zeMel"
      },
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fv63ddnSOG-"
      },
      "source": [
        "Sau đó, bạn sẽ cần khai báo cho hệ thống các đường dẫn cho các thành phần vừa cài."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8gN9Zhx8vPb"
      },
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\"\n",
        "\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM4wpiJMTCib"
      },
      "source": [
        "# Kết nối với Google Drive\n",
        "\n",
        "Để lấy dữ liệu từ các Dataset, bạn sẽ phải lưu file dữ liệu lên Google Drive. Sau đó kết nối Colab đến Google Drive của bạn và lấy được các file dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoYnrNV7UChX",
        "outputId": "6cf8a6e5-fe13-48cb-d740-d3917d920032"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWim4uwkxMdATVTutjcI7B8CH2rnTy9v2LJ8GOXkVBWl-wbdkSOj_1E\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0yzaQQNDKoV"
      },
      "source": [
        "# Source and Slink\n",
        "\n",
        "Bạn sẽ cần khởi tạo 1 SparkSesson để có thể bắt đầu Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjqT5XXj80P8"
      },
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, DateType, StringType, IntegerType\n",
        "from pyspark.sql.functions import spark_partition_id\n",
        "\n",
        "conf = SparkConf() \\\n",
        "    .setMaster('local') \\\n",
        "    .setAppName('[...]')\n",
        "\n",
        "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "DATASET_PATH = '[...]flight-time.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q12Bu68-wkqq"
      },
      "source": [
        "Đọc dữ liệu bằng cách sử dụng StructType Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyrh2wUTwgXQ"
      },
      "source": [
        "flightSchemaStruct = StructType([\n",
        "  [...]\n",
        "])\n",
        "\n",
        "print('Schema by StructType')\n",
        "flightTimeCsvDF = spark.read \\\n",
        "    .format([...]) \\\n",
        "    .option(\"header\", [...]) \\\n",
        "    .schema([...]) \\\n",
        "    .option(\"mode\", \"FAILFAST\") \\\n",
        "    .option(\"dateFormat\", [...]) \\\n",
        "    .load(DATASET_PATH)\n",
        "\n",
        "flightTimeCsvDF.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiSmnmH8wwc2"
      },
      "source": [
        "Đọc dữ liệu bằng cách sử dụng String Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAvU7CF7sVXg",
        "outputId": "8d03f5a8-3a7d-4914-e820-d6ed2e6a998b"
      },
      "source": [
        "flightSchemaDDL = [...]\n",
        "\n",
        "\n",
        "print('Schema by String')\n",
        "flightTimeCsvDF = spark.read \\\n",
        "    .format([...]) \\\n",
        "    .option(\"header\", [...]) \\\n",
        "    .schema([...]) \\\n",
        "    .option(\"mode\", \"FAILFAST\") \\\n",
        "    .option(\"dateFormat\", [...]) \\\n",
        "    .load(DATASET_PATH)\n",
        "\n",
        "\n",
        "flightTimeCsvDF.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema by StructType\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|ORIGIN_CITY_NAME|DEST|DEST_CITY_NAME|CRS_DEP_TIME|DEP_TIME|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|CANCELLED|DISTANCE|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|2000-01-01|        DL|             1451|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1115|    1113|     1343|      5|        1400|    1348|        0|     946|\n",
            "|2000-01-01|        DL|             1479|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1315|    1311|     1536|      7|        1559|    1543|        0|     946|\n",
            "|2000-01-01|        DL|             1857|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1415|    1414|     1642|      9|        1721|    1651|        0|     946|\n",
            "|2000-01-01|        DL|             1997|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1715|    1720|     1955|     10|        2013|    2005|        0|     946|\n",
            "|2000-01-01|        DL|             2065|   BOS|      Boston, MA| ATL|   Atlanta, GA|        2015|    2010|     2230|     10|        2300|    2240|        0|     946|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Schema by String\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|ORIGIN_CITY_NAME|DEST|DEST_CITY_NAME|CRS_DEP_TIME|DEP_TIME|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|CANCELLED|DISTANCE|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|2000-01-01|        DL|             1451|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1115|    1113|     1343|      5|        1400|    1348|        0|     946|\n",
            "|2000-01-01|        DL|             1479|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1315|    1311|     1536|      7|        1559|    1543|        0|     946|\n",
            "|2000-01-01|        DL|             1857|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1415|    1414|     1642|      9|        1721|    1651|        0|     946|\n",
            "|2000-01-01|        DL|             1997|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1715|    1720|     1955|     10|        2013|    2005|        0|     946|\n",
            "|2000-01-01|        DL|             2065|   BOS|      Boston, MA| ATL|   Atlanta, GA|        2015|    2010|     2230|     10|        2300|    2240|        0|     946|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTkFiQ8a0104"
      },
      "source": [
        "Tiếp theo đó bạn cần phải phân vùng lại cho dữ liệu và lưu dữ liệu đó ra file. Đầu tiên hãy phân vùng dữ liệu thành **5** vùng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dccanhlM0O4S",
        "outputId": "dde65207-afc5-4252-dbe7-fc28876dcd50"
      },
      "source": [
        "flightTimeCsvDF.groupBy(spark_partition_id()).count().show()\n",
        "print(\"Num Partitions before: \" + str(flightTimeCsvDF.rdd.getNumPartitions()))\n",
        "\n",
        "\n",
        "partitionedDF = [...]\n",
        "print(\"Num Partitions after: \" + str(partitionedDF.rdd.getNumPartitions()))\n",
        "partitionedDF.groupBy(spark_partition_id()).count().show()\n",
        "\n",
        "partitionedDF.[...] \\\n",
        "    .format(\"json\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"path\", \"./dataSink/avro/\") \\\n",
        "    .save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|SPARK_PARTITION_ID()| count|\n",
            "+--------------------+------+\n",
            "|                   0|470477|\n",
            "+--------------------+------+\n",
            "\n",
            "Num Partitions before: 1\n",
            "Num Partitions after: 5\n",
            "+--------------------+-----+\n",
            "|SPARK_PARTITION_ID()|count|\n",
            "+--------------------+-----+\n",
            "|                   1|94096|\n",
            "|                   3|94095|\n",
            "|                   4|94095|\n",
            "|                   2|94096|\n",
            "|                   0|94095|\n",
            "+--------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ewPuoD11iL"
      },
      "source": [
        "Ngoài ra, bạn có có thể phân vùng lại theo các trường. Hãy hoàn thiện đoạn code để phân vùng theo hai trường là `\"OP_CARRIER\"` và `\"ORIGIN\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGTHBSRnyVLq"
      },
      "source": [
        "flightTimeCsvDF.[...] \\\n",
        "    .format(\"json\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"path\", \"dataSink/json/\") \\\n",
        "    .partitionBy([...]) \\\n",
        "    .option(\"maxRecordsPerFile\", 10000) \\\n",
        "    .save()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}